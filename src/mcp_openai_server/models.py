"""Data models for MCP OpenAI Server."""

from typing import Dict, List, Literal, Optional, Union

from pydantic import BaseModel, Field


class ChatMessage(BaseModel):
    """A chat message in the conversation."""
    
    role: Literal["system", "user", "assistant", "tool"] = Field(
        description="The role of the message author"
    )
    content: str = Field(
        description="The content of the message"
    )
    name: Optional[str] = Field(
        default=None,
        description="An optional name for the participant"
    )


class ChatCompletionRequest(BaseModel):
    """Request model for chat completion."""
    
    messages: List[ChatMessage] = Field(
        min_length=1,
        description="A list of messages comprising the conversation so far"
    )
    model: Optional[str] = Field(
        default=None,
        description="ID of the model to use. If not provided, uses the default model"
    )
    max_tokens: Optional[int] = Field(
        default=None,
        description="The maximum number of tokens to generate"
    )
    temperature: Optional[float] = Field(
        default=None,
        description="Sampling temperature between 0 and 2"
    )
    top_p: Optional[float] = Field(
        default=None,
        description="Nucleus sampling parameter"
    )
    frequency_penalty: Optional[float] = Field(
        default=None,
        description="Frequency penalty between -2.0 and 2.0"
    )
    presence_penalty: Optional[float] = Field(
        default=None,
        description="Presence penalty between -2.0 and 2.0"
    )
    stop: Optional[Union[str, List[str]]] = Field(
        default=None,
        description="Up to 4 sequences where the API will stop generating tokens"
    )
    stream: Optional[bool] = Field(
        default=False,
        description="Whether to stream back partial progress"
    )


class ChatCompletionChoice(BaseModel):
    """A choice in the chat completion response."""
    
    index: int = Field(
        description="The index of this choice in the list of choices"
    )
    message: ChatMessage = Field(
        description="The message generated by the model"
    )
    finish_reason: Optional[str] = Field(
        description="The reason the model stopped generating tokens"
    )


class ChatCompletionUsage(BaseModel):
    """Usage statistics for the chat completion."""
    
    prompt_tokens: int = Field(
        description="Number of tokens in the prompt"
    )
    completion_tokens: int = Field(
        description="Number of tokens in the completion"
    )
    total_tokens: int = Field(
        description="Total number of tokens used"
    )


class ChatCompletionResponse(BaseModel):
    """Response model for chat completion."""
    
    id: str = Field(
        description="A unique identifier for the chat completion"
    )
    object: str = Field(
        default="chat.completion",
        description="The object type, which is always 'chat.completion'"
    )
    created: int = Field(
        description="The Unix timestamp when the chat completion was created"
    )
    model: str = Field(
        description="The model used for the chat completion"
    )
    choices: List[ChatCompletionChoice] = Field(
        description="A list of chat completion choices"
    )
    usage: ChatCompletionUsage = Field(
        description="Usage statistics for the completion request"
    )
    system_fingerprint: Optional[str] = Field(
        default=None,
        description="System fingerprint for the response"
    )